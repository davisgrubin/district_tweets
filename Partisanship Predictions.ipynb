{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This notebook is for reproducing the results from my Galvanize DSI capstone.\n",
    "## Let GeoStream.py run in a terminal to populate the stream_tweets directory until you have around 8gb\n",
    "## of tweets (this is assuming you haven't filtered out any metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DistrictDict as dd\n",
    "import tweets_to_df as t2df\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "import re\n",
    "import preprocess_twitter as pre\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads tweets from stream_tweets file into df format, then saves it to a pikl file.\n",
    "t2df.tweets2df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = t2df.get_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 = Republican, 0 = Democrats\n",
    "y = tweets_df.party\n",
    "#Treating all tweets from each district as one \"document\" in a binary classification task. \n",
    "x = [\" \".join(i) for i in tweets_df['text']]\n",
    "#Stanford pre-processing script\n",
    "x = [pre.tokenize(i) for i in x]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we predict the party of representatives from a district solely based off of a Bag of Words or Tf-idf\n",
    "# and Naive Bayes approach?\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "#Feature Extraction\n",
    "bag_of_words = CountVectorizer(stop_words=\"english\",max_df=.95,min_df=20).fit_transform(x_train)\n",
    "tfidf = TfidfVectorizer(stop_words='english',max_df=.95,min_df=20).fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performing 3-fold cross validation for all methods\n",
    "## if you have too few tweets these will throw up NaN/infinity input errors. \n",
    "scores = cross_val_score(MultinomialNB(),bag_of_words,y_train)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(MultinomialNB(),tfidf,y_train)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                       alpha=1e-3, random_state=42,\n",
    "                                       max_iter=1000, tol=None),bag_of_words,y_train)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                       alpha=1e-3, random_state=42,\n",
    "                                       max_iter=1000, tol=None),tfidf,y_train)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting percentage of Republican districts to make sure \n",
    "#we have balanced enough classes that accuracy is a good measure\n",
    "sum(y_train==1)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try some dimensionality reduction of tfidf matrix. \n",
    "lsa_tfidf = TruncatedSVD(n_components=50).fit_transform(tfidf)\n",
    "scores = cross_val_score(SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                       alpha=1e-3,random_state=42,\n",
    "                                       max_iter=20, tol=None),lsa_tfidf,y_train)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "scores = cross_val_score(CatBoostClassifier(),lsa_tfidf,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
